{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import click\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/dti_store/graph_2.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_ensemdt(data_path):\n",
    "    print (\"Loading data from disk...\")\n",
    "    \n",
    "    with open(data_path) as f:\n",
    "        graph = pickle.load(f)\n",
    "    num_u, num_v, u_nodes, v_nodes, y, u_feat, v_feat = graph\n",
    "    \n",
    "    print (\"Total no. of nodes =\", y.shape[0])\n",
    "    print (\"Shape of drug feature tensor =\", u_feat.shape)\n",
    "    print (\"Shape of target feature tensor =\", v_feat.shape)\n",
    "    print (\"\")\n",
    "    \n",
    "    df = np.vstack([u_nodes, v_nodes, y])\n",
    "    df_transpose = df.T\n",
    "    df = pd.DataFrame(df_transpose, columns=['u_node', 'v_node', 'y'])\n",
    "    \n",
    "    df_pos = df[df['y'] == 1]\n",
    "    df_neg = df[df['y'] == 0]\n",
    "    \n",
    "    u_feat = u_feat.toarray()\n",
    "    v_feat = v_feat.toarray()\n",
    "    \n",
    "    u_feat_headers = ['d' + str(i + 1) for i in range(u_feat.shape[1])]\n",
    "    v_feat_headers = ['t' + str(i + 1) for i in range(v_feat.shape[1])]\n",
    "    \n",
    "    df_u = pd.DataFrame(u_feat, columns=u_feat_headers)\n",
    "    df_v = pd.DataFrame(v_feat, columns=v_feat_headers)\n",
    "    \n",
    "    print (\"Shape of df_u =\", df_u.shape)\n",
    "    print (\"Shape of df_v =\", df_v.shape)\n",
    "    print (\"Shape of df_pos =\", df_pos.shape)\n",
    "    print (\"Shape of df_neg =\", df_neg.shape)\n",
    "\n",
    "    return df_pos, df_neg, df_u, df_v\n",
    "\n",
    "\n",
    "def train_test_split_ensemdt(df_pos, df_neg, test_size=0.2, shuffle=True):\n",
    "    # Remove y from pos and neg set\n",
    "    y_pos = df_pos['y']\n",
    "    y_neg = df_neg['y']\n",
    "    \n",
    "    df_pos_split = df_pos.drop(['y'], axis=1)\n",
    "    df_neg_split = df_neg.drop(['y'], axis=1)\n",
    "    \n",
    "    # Split into pos and neg train and test sets\n",
    "    X_train_pos, X_test_pos, y_train_pos, y_test_pos = train_test_split(df_pos_split, \n",
    "                                                    y_pos, test_size=test_size, random_state=42)\n",
    "    X_train_neg, X_test_neg, y_train_neg, y_test_neg = train_test_split(df_neg_split, \n",
    "                                                    y_neg, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Recombine to form test set\n",
    "    X_test_pos['y'] = y_test_pos\n",
    "    X_test_neg['y'] = y_test_neg\n",
    "    \n",
    "    X_test = pd.concat([X_test_pos, X_test_neg])\n",
    "    \n",
    "    # Re-enter test labels\n",
    "    X_train_pos['y'] = y_train_pos\n",
    "    X_train_neg['y'] = y_train_neg\n",
    "    \n",
    "    # Shuffle test set\n",
    "    if shuffle:\n",
    "        X_test = X_test.sample(frac=1)\n",
    "        \n",
    "    y_test = np.array(X_test['y'])\n",
    "    X_test = X_test.drop(['y'], axis=1)\n",
    "    \n",
    "    return X_train_pos, X_train_neg, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from disk...\n",
      "Total no. of nodes = 104809\n",
      "Shape of drug feature tensor = (1862, 881)\n",
      "Shape of target feature tensor = (1554, 876)\n",
      "\n",
      "Shape of df_u = (1862, 881)\n",
      "Shape of df_v = (1554, 876)\n",
      "Shape of df_pos = (4809, 3)\n",
      "Shape of df_neg = (100000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedang/.local/lib/python2.7/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/vedang/.local/lib/python2.7/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/vedang/.local/lib/python2.7/site-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/vedang/.local/lib/python2.7/site-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_pos, df_neg, df_u, df_v = load_data_ensemdt(DATA_PATH)\n",
    "X_train_pos, X_train_neg, X_test, y_test = train_test_split_ensemdt(df_pos, df_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsemDT:\n",
    "    \n",
    "    def __init__(self, n_estimators=50, dim_red_ratio=0.9, \n",
    "                 np_ratio=5, reduce_dims=True, n_components=100,\n",
    "                 max_depth=None):\n",
    "        \n",
    "        self.n_estimators = n_estimators\n",
    "        self.dim_red_ratio = dim_red_ratio\n",
    "        self.np_ratio = np_ratio\n",
    "        self.reduce_dims = reduce_dims\n",
    "        self.n_components = n_components\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        self.clfs = list()\n",
    "        \n",
    "    def fit(self, df_pos, df_neg, df_u, df_v):\n",
    "        self.num_pos = df_pos.shape[0]\n",
    "        self.df_u = df_u\n",
    "        self.df_v = df_v\n",
    "        \n",
    "        self.training_time = time()\n",
    "        \n",
    "        for i in tqdm(range(self.n_estimators), desc='Training model...', unit='base learner'):\n",
    "            df_neg_sampled = df_neg.sample(self.np_ratio*self.num_pos)\n",
    "            \n",
    "            training_set = pd.concat([df_neg_sampled, df_pos])\n",
    "            \n",
    "            subspace_u = random.sample(range(self.df_u.shape[1]), \n",
    "                                       int(self.dim_red_ratio*self.df_u.shape[1]))\n",
    "            subspace_v = random.sample(range(self.df_v.shape[1]),\n",
    "                                       int(self.dim_red_ratio*self.df_v.shape[1]))\n",
    "\n",
    "            head_u = ['d' + str(i+1) for i in subspace_u]\n",
    "            head_v = ['t' + str(i+1) for i in subspace_v]\n",
    "            \n",
    "            df_u_sub = self.df_u[head_u]\n",
    "            df_v_sub = self.df_v[head_v]\n",
    "            \n",
    "            if self.reduce_dims:\n",
    "                pca_u = PCA(n_components=self.n_components)\n",
    "                pca_v = PCA(n_components=self.n_components)\n",
    "\n",
    "                df_u_sub = pca_u.fit_transform(df_u_sub)\n",
    "                df_v_sub = pca_v.fit_transform(df_v_sub)\n",
    "            \n",
    "            data = []\n",
    "            labels = []\n",
    "\n",
    "            for _, row in training_set.iterrows():\n",
    "                try:\n",
    "                    data.append(np.concatenate([df_u_sub[row['u_node']], df_v_sub[row['v_node']]], axis=0))\n",
    "                    labels.append(row['y'])\n",
    "                except:\n",
    "                    print (\"Skipping \" + str(row['u_node']) + \" \" + str(row['v_node']) + \"...\")\n",
    "            y = np.vstack(labels)\n",
    "            y = np.reshape(y, (y.shape[0],))\n",
    "                    \n",
    "            X = np.vstack(data)\n",
    "            \n",
    "            dt = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            dt.fit(X, y)\n",
    "            \n",
    "            base_learner = {'clf': dt, \n",
    "                            'u_cols': head_u, \n",
    "                            'v_cols': head_v}\n",
    "            \n",
    "            self.clfs.append(base_learner)\n",
    "            \n",
    "        self.training_time = time() - self.training_time\n",
    "        \n",
    "    \n",
    "    def predict(self, df_test):\n",
    "        preds = list()\n",
    "        \n",
    "        for i in tqdm(range(self.n_estimators), desc='Testing model...', unit='base learner'):\n",
    "            base_learner = self.clfs[i]\n",
    "            \n",
    "            head_u = base_learner['u_cols']\n",
    "            head_v = base_learner['v_cols']\n",
    "            \n",
    "            df_u_sub = self.df_u[head_u]\n",
    "            df_v_sub = self.df_v[head_v]\n",
    "            \n",
    "            if self.reduce_dims:\n",
    "                pca_u = PCA(n_components=self.n_components)\n",
    "                pca_v = PCA(n_components=self.n_components)\n",
    "\n",
    "                df_u_sub = pca_u.fit_transform(df_u_sub)\n",
    "                df_v_sub = pca_v.fit_transform(df_v_sub)\n",
    "            \n",
    "            data = []\n",
    "\n",
    "            for _, row in df_test.iterrows():\n",
    "                try:\n",
    "                    data.append(np.concatenate([df_u_sub[row['u_node']], df_v_sub[row['v_node']]], axis=0))\n",
    "                except:\n",
    "                    print (\"Skipping \" + str(row['u_node']) + \" \" + str(row['v_node']) + \"...\")\n",
    "                    \n",
    "            X_test = np.vstack(data)\n",
    "            \n",
    "            clf = base_learner['clf']\n",
    "            pred = clf.predict(X_test)\n",
    "            preds.append(pred)\n",
    "            \n",
    "        preds = np.vstack(preds)\n",
    "        final_preds = np.sum(preds, axis=0).astype(np.float32)\n",
    "        final_preds /= self.n_estimators\n",
    "        \n",
    "        return final_preds\n",
    "    \n",
    "    def predict_proba(self, df_test):\n",
    "        preds = list()\n",
    "        \n",
    "        for i in tqdm(range(self.n_estimators), desc='Testing model...', unit='base learner'):\n",
    "            base_learner = self.clfs[i]\n",
    "            \n",
    "            head_u = base_learner['u_cols']\n",
    "            head_v = base_learner['v_cols']\n",
    "            \n",
    "            df_u_sub = self.df_u[head_u]\n",
    "            df_v_sub = self.df_v[head_v]\n",
    "            \n",
    "            if self.reduce_dims:\n",
    "                pca_u = PCA(n_components=self.n_components)\n",
    "                pca_v = PCA(n_components=self.n_components)\n",
    "\n",
    "                df_u_sub = pca_u.fit_transform(df_u_sub)\n",
    "                df_v_sub = pca_v.fit_transform(df_v_sub)\n",
    "            \n",
    "            data = []\n",
    "\n",
    "            for _, row in df_test.iterrows():\n",
    "                try:\n",
    "                    data.append(np.concatenate([df_u_sub[row['u_node']], df_v_sub[row['v_node']]], axis=0))\n",
    "                except:\n",
    "                    print (\"Skipping \" + str(row['u_node']) + \" \" + str(row['v_node']) + \"...\")\n",
    "                    \n",
    "            X_test = np.vstack(data)\n",
    "            \n",
    "            clf = base_learner['clf']\n",
    "            pred = clf.predict_proba(X_test)[:, 1]\n",
    "            preds.append(pred)\n",
    "            \n",
    "        preds = np.vstack(preds)\n",
    "        final_preds = np.sum(preds, axis=0).astype(np.float32)\n",
    "        final_preds /= self.n_estimators\n",
    "        \n",
    "        return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pos.shape, X_train_neg.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 50/50 [03:22<00:00,  4.00s/base learner]\n"
     ]
    }
   ],
   "source": [
    "ensem_dt = EnsemDT(max_depth=1)\n",
    "ensem_dt.fit(X_train_pos, X_train_neg, df_u, df_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing model...: 100%|██████████| 50/50 [02:37<00:00,  3.11s/base learner]\n"
     ]
    }
   ],
   "source": [
    "pred = ensem_dt.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedang/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Series.data is deprecated and will be removed in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6016004937629937"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
